from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import requests
import io
import urllib.parse
import os
import random
import logging
import base64
import time

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

HF_API_KEY = os.getenv('HF_API_KEY')
PROXY_SERVER_URL = os.getenv('PROXY_SERVER_URL', 'https://gemini-proxy.up.railway.app')

def translate_with_deepseek(text):
    """–ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ DeepSeek API"""
    logger.info(f"üß† –ü–µ—Ä–µ–≤–æ–¥: '{text}'")
    try:
        response = requests.post(
            'https://api.deepseek.com/v1/chat/completions',
            headers={'Content-Type': 'application/json'},
            json={
                'model': 'deepseek-chat',
                'messages': [
                    {
                        'role': 'system', 
                        'content': 'You are a professional translator. Translate Russian to English accurately. Return only the translation without any additional text.'
                    },
                    {
                        'role': 'user', 
                        'content': f'Translate this to English: "{text}"'
                    }
                ],
                'temperature': 0.1,
                'max_tokens': 1000
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            translation = result['choices'][0]['message']['content'].strip().strip('"')
            logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–µ–ª: '{translation}'")
            return translation
        else:
            logger.error(f"‚ùå DeepSeek —Å—Ç–∞—Ç—É—Å: {response.status_code}")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return None

def translate_text(text):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    if not any(char.lower() in '–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è' for char in text):
        return text
    
    translation = translate_with_deepseek(text)
    return translation if translation else text

def generate_with_gemini_proxy(prompt, image_data=None):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –Ω–∞—à –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä"""
    try:
        proxy_url = f"{PROXY_SERVER_URL}/generate-image"
        
        payload = {
            'prompt': prompt
        }
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ base64
        if image_data:
            payload['imageData'] = base64.b64encode(image_data).decode('utf-8')
        
        logger.info(f"üéØ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ –ø—Ä–æ–∫—Å–∏: '{prompt}'")
        logger.info(f"üîó URL –ø—Ä–æ–∫—Å–∏: {proxy_url}")
        
        response = requests.post(
            proxy_url,
            json=payload,
            timeout=120  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        )
        
        logger.info(f"üì° –°—Ç–∞—Ç—É—Å –ø—Ä–æ–∫—Å–∏: {response.status_code}")
        
        if response.status_code == 200:
            logger.info("‚úÖ –ü—Ä–æ–∫—Å–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
            return response.content
        else:
            error_text = response.text[:500] if response.text else "No error details"
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–∫—Å–∏: {error_text}")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ø—Ä–æ–∫—Å–∏: {e}")
        return None

def generate_with_hf_img2img(prompt, image_data, strength=0.7):
    """–ù–∞—Å—Ç–æ—è—â–∏–π img2img —á–µ—Ä–µ–∑ Hugging Face"""
    try:
        logger.info("üé® –ò—Å–ø–æ–ª—å–∑—É–µ–º Hugging Face img2img...")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
        image_b64 = base64.b64encode(image_data).decode('utf-8')
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç img2img
        models = [
            "runwayml/stable-diffusion-v1-5",
            "stabilityai/stable-diffusion-2-1",
        ]
        
        for model in models:
            logger.info(f"üîß –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª—å: {model}")
            
            url = f"https://api-inference.huggingface.co/models/{model}"
            headers = {"Authorization": f"Bearer {HF_API_KEY}"} if HF_API_KEY else {}
            
            payload = {
                "inputs": f"{prompt}",
                "parameters": {
                    "image": image_b64,
                    "strength": strength,
                    "guidance_scale": 7.5,
                    "num_inference_steps": 20
                }
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            logger.info(f"üì° –°—Ç–∞—Ç—É—Å {model}: {response.status_code}")
            
            if response.status_code == 200:
                logger.info(f"‚úÖ –£—Å–ø–µ—Ö —Å –º–æ–¥–µ–ª—å—é {model}!")
                return response.content
            elif response.status_code == 503:
                logger.info(f"‚è≥ –ú–æ–¥–µ–ª—å {model} –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
                continue
            else:
                logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞: {response.text[:100]}")
        
        return None
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ HF img2img: {e}")
        return None

def generate_fallback_img2img(prompt, image_data):
    """Fallback - —É–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback (—É–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç)...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        from PIL import Image
        import io
        
        img = Image.open(io.BytesIO(image_data))
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤
        colors = img.getcolors(maxcolors=256)
        if colors:
            dominant_color = max(colors, key=lambda x: x[0])[1]
            color_desc = f" with dominant {('red', 'green', 'blue', 'yellow', 'purple', 'orange')[dominant_color[0] % 6]} tones"
        else:
            color_desc = ""
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        width, height = img.size
        if width > height:
            orientation = "landscape"
        elif height > width:
            orientation = "portrait" 
        else:
            orientation = "square"
        
        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        enhanced_prompt = f"{prompt} - editing the uploaded {orientation} image{color_desc} while preserving original composition"
        
        logger.info(f"üí° –£–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç: '{enhanced_prompt}'")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pollinations
        encoded_prompt = urllib.parse.quote(enhanced_prompt)
        url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?model=nanobanano&width={width}&height={height}"
        
        response = requests.get(url, timeout=60)
        if response.status_code == 200:
            return response.content
        
        return None
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ fallback: {e}")
        return None

@app.route('/generate', methods=['POST'])
def generate_image_route():
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        if request.content_type and request.content_type.startswith('multipart/form-data'):
            prompt = request.form.get('prompt', '')
            model_name = request.form.get('model', 'nanobanano')
            image_file = request.files.get('image')
            edit_mode = request.form.get('edit_mode', 'false').lower() == 'true'
        else:
            data = request.get_json() or {}
            prompt = data.get('prompt', '')
            model_name = data.get('model', 'nanobanano')
            image_file = None
            edit_mode = data.get('edit_mode', False)
        
        if not prompt:
            return jsonify({"error": "–ü—Ä–æ–º–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º"}), 400
        
        logger.info(f"üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: '{prompt}'")
        logger.info(f"üîß –ú–æ–¥–µ–ª—å: {model_name}")
        logger.info(f"üìù –†–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {edit_mode}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        image_data = None
        if image_file and image_file.filename:
            logger.info("üñºÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
            image_data = image_file.read()
            logger.info(f"üìä –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {len(image_data)} bytes")
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Gemini –ø—Ä–æ–∫—Å–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            if PROXY_SERVER_URL:
                logger.info("üöÄ –ü—Ä–æ–±—É–µ–º Gemini –ø—Ä–æ–∫—Å–∏...")
                result = generate_with_gemini_proxy(prompt, image_data)
                if result:
                    logger.info("‚úÖ Gemini –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                    return send_file(io.BytesIO(result), mimetype='image/png')
                else:
                    logger.warning("‚ö†Ô∏è Gemini –ø—Ä–æ–∫—Å–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª")
            
            # Fallback –Ω–∞ –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã
            logger.info("üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ fallback –º–µ—Ç–æ–¥–∞–º...")
            result = generate_with_hf_img2img(prompt, image_data)
            if not result:
                result = generate_fallback_img2img(prompt, image_data)
            
            if result:
                logger.info("‚úÖ Img2Img —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω —á–µ—Ä–µ–∑ fallback!")
                return send_file(io.BytesIO(result), mimetype='image/png')
            else:
                logger.warning("‚ö†Ô∏è –í—Å–µ –º–µ—Ç–æ–¥—ã img2img –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
                return jsonify({"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"}), 500
        
        # –û–±—ã—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (text2img)
        translated_prompt = translate_text(prompt)
        logger.info(f"üåê –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç: '{translated_prompt}'")
        
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini
        if edit_mode and PROXY_SERVER_URL:
            logger.info("üéØ –†–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –ø—Ä–æ–±—É–µ–º Gemini...")
            result = generate_with_gemini_proxy(translated_prompt)
            if result:
                return send_file(io.BytesIO(result), mimetype='image/png')
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pollinations
        encoded_prompt = urllib.parse.quote(translated_prompt)
        seed = random.randint(1, 1000000)
        
        if model_name in ["nanobanano", "pollinations", "flux", "dalle", "stable-diffusion", "midjourney"]:
            url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?model={model_name}&width=512&height=512&seed={seed}"
            response = requests.get(url, timeout=60)
        else:
            url = f"https://api-inference.huggingface.co/models/{model_name}"
            headers = {"Authorization": f"Bearer {HF_API_KEY}"} if HF_API_KEY else {}
            response = requests.post(url, headers=headers, json={
                "inputs": translated_prompt,
                "options": {"wait_for_model": True}
            }, timeout=60)
        
        logger.info(f"üì° –°—Ç–∞—Ç—É—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {response.status_code}")
        
        if response.status_code == 200:
            logger.info("‚úÖ –£–°–ü–ï–•: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
            return send_file(io.BytesIO(response.content), mimetype='image/png')
        else:
            error_msg = response.text[:200] if response.text else "Unknown error"
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {error_msg}")
            return jsonify({"error": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {error_msg}"}), 500
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        return jsonify({"error": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"}), 500

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "OK", 
        "message": "–°–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç",
        "proxy_url": PROXY_SERVER_URL
    })

if __name__ == '__main__':
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞...")
    logger.info(f"üîó Proxy URL: {PROXY_SERVER_URL}")
    app.run(host='0.0.0.0', port=5000, debug=False)
